<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Website</title>
    <link rel="stylesheet" href="main.css">
</head>
<body class="light-theme">

    <!-- Navigation -->
    <!--<div class="navbar">
        <a href="index.html" class="navbar-item">Home </a>
        <a href="projects.html" class="navbar-item">/ Projects </a>
        <!--<a href="interests.html" class="navbar-item">/ Other Interests </a>-->
    <!--</div> -->
    
    <img src="phil_circle.png" alt="phil_circle" width="225" height="225">
    <h1>Phil D.</h1>
    <p id="msg">I am currently pursuing a dual-degree Master of Science in Engineering (MSE) in Robotics (ROBO) and Computer and Information Science (CIS)
        at the University of Pennsylvania, where I am part of the <a style="text-decoration: underline; color: blue;" rel="Click here" href="https://www.grasp.upenn.edu/">GRASP Lab</a>.
        My research interests focus on robotics, computer vision, and the development of scalable, safe perception systems.</br>
    </br>
        As a Research Assistant at xLab (under Prof. Rahul Mangharam), I contributed to the design, development, and deployment of an infrastructure-based system for autonomous navigation, focused on warehouse automation.
        In addition, I served as the Head Teaching Assistant for CIS 5810 Computer Vision & Computational Photography (under Prof. Jianbo Shi).
        I hold a Bachelor's degree in Economics from Johns Hopkins University.</br>
    </p>
    </br>
    <h2>Research</h2>
    <p id="msg">Research Assistant, xLab - Safe Autonomous Systems Lab</br>
        Infrastructure-based system for autonomous navigation, focused on warehouse automation (RetroLifts)</br>
        <em>Summer 2024, Fall 2024</em>
    </p>
    <br>
    <h2>Teaching</h2>
    <p id="msg">Head Teaching Assistant, CIS 5810 Computer Vision & Computational Photography<br>
        <em>Summer 2022, Fall 2022, Spring 2023, Fall 2023, Fall 2024</em>
    </p>
    <p id="msg">Head Teaching Assistant, ENGR 2900 Penn Global Seminar: Artificial Intelligence & Robotics<br>
        <em>Spring 2024</em>
    </p>
    <br>
    <h2>Awards</h2>
    <p id="msg">TA Award (Student Nominated), CIS 5810 Computer Vision & Computational Photography<br>
        <em>Summer 2022</em>
    </p>
    <br>
    <h2>Selected projects and research</h2>
    <p id="msg"></p>
        <img src="positioning_perspective_demo.gif" alt="positioning perspective" width="350" height="225">
        <img src="positioning_map_demo.gif" alt="positioning map" width="350" height="225"><br>
        Real-time positioning system for robots<br>
        <em>Developed a real-time object positioning system using monocular cameras.</em>
        <!--<a href="https://github.com/philprojxsphilprojxs">See code in GitHub.</a><br>-->
    </p>
    <p id="msg">
        <img src="lane_detection_night_demo.gif" alt="lane detection night" width="350" height="225">
        <img src="lane_detection_day_demo.gif" alt="lane detection day" width="350" height="225"><br>
        Lane detection model for autonomous vehicles<br>
        <em>Developed and trained a transformer-based computer vision model to detect and segment street lane markers for autonomous driving applications.</em>
        <!--<a href="https://github.com/philprojxs">See code in GitHub.</a><br>-->
    </p>
    <p id="msg"></p>
        <img src="techvest_demo.gif" alt="techvest" width="350" height="225"><br>
        VitalTech SmartVest: Exploring biometric monitoring through the use of computational textiles during exercise foor injury and disease prevention<br>
        <em>Designed and developed a wearable, cost-efficient vest prototype that monitors and analyzes biometric data (e.g., body temperature, movement and orientation, heart rate) during physical activity, enabling real-time health tracking to prevent injuries and disease.</em>
        <!--<a href="https://github.com/philprojxs">See code in GitHub.</a><br>-->
    </p>
    <p id="msg">
        <img src="text_to_object_segmentation_demo.gif" alt="text to object segmentation" width="350" height="225"><br>
        Text-to-object segmentation pipeline<br>
        <em>Developed a pipeline for semantic object detection using category-specific bounding box prompts, enabling targeted segmentation and improving data annotation efficiency.</em>
        <!--<a href="https://github.com/philprojxs">See code in GitHub.</a><br>-->
    </p>
    <p id="msg">
        <img src="automated_prompting_demo.png" alt="automated prompting" width="350" height="225"><br>
        Automated prompting for segmentation<br>
        <em>Conducted research to develop a framework that enhances Meta’s Segment Anything Model (SAM) by improving segmentation accuracy for targeted objects, particularly in cases where SAM’s bounding box prompts failed to fully segment the desired object.</em>
        <!--<a href="https://github.com/philprojxs">See code in GitHub.</a><br>-->
    </p>
    <p id="msg">
        <img src="driver_risk_recognition_demo.gif" alt="driver risk recognition" width="350" height="225"><br>
        Driver risk recognition platform<br>
        <em> Designed and developed an application that detects when a driver is unfit to operate a vehicle (e.g. due to drowsiness or failure to properly scan the road).</em>
        <!--<a href="https://github.com/philprojxs">See code in GitHub.</a><br>-->
    </p>
    <br>
    <h2>Misc</h2>
    <p id="msg">I enjoy electronic/metal/punk rock music, movies/tv series, watching baseball, and exploring neighborhoods (and food).<br>
    </p>
    <img src="futuristic_city.jpeg" alt="Futuristic city" width="375" height="300">
    <div>
        <!--<button class="btn">Dark</button>-->
    </div>
    <script src="app.js"></script>
    <noscript>You need to enable JavaScript to view the full site.</noscript>
</body>
</html>